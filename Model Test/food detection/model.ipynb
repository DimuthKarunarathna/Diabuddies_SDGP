{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "m = hub.KerasLayer('https://tfhub.dev/google/aiy/vision/classifier/food_V1/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFood_url = \"foodimage2.jpeg\"\n",
    "labelmap_url = \"aiy_food_V1_labelmap.csv\"\n",
    "input_shape = (224, 224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.asarray(io.imread(inputFood_url), dtype=\"float\")\n",
    "image = cv2.resize(image, dsize=input_shape, interpolation=cv2.INTER_CUBIC)\n",
    "# Scale values to [0, 1].\n",
    "image = image / image.max()\n",
    "image = image.astype(np.float32)\n",
    "# The model expects an input of (?, 224, 224, 3).\n",
    "images = np.expand_dims(image, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  Waffle\n"
     ]
    }
   ],
   "source": [
    "output = m(images)\n",
    "predicted_index = output.numpy().argmax()\n",
    "classes = list(pd.read_csv(labelmap_url)[\"name\"])\n",
    "print(\"Prediction: \", classes[predicted_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as keras_layer_1_layer_call_fn, keras_layer_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/lk/7j1rwkqx2w1f1m__90437jbc0000gn/T/tmpt8vpdkvj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/lk/7j1rwkqx2w1f1m__90437jbc0000gn/T/tmpt8vpdkvj/assets\n",
      "2023-04-05 12:40:46.307824: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-04-05 12:40:46.308014: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(m)\n",
    "tflite_model = converter.convert()\n",
    "with open('food_classifier.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Got value of type FLOAT64 but expected type FLOAT32 for input 0, name: serving_default_images:0 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(image, \u001b[39m0\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[39m# Set the input tensor.\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m interpreter\u001b[39m.\u001b[39;49mset_tensor(input_details[\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mindex\u001b[39;49m\u001b[39m'\u001b[39;49m], image)\n\u001b[1;32m     25\u001b[0m \u001b[39m# Invoke the interpreter.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m interpreter\u001b[39m.\u001b[39minvoke()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:696\u001b[0m, in \u001b[0;36mInterpreter.set_tensor\u001b[0;34m(self, tensor_index, value)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_tensor\u001b[39m(\u001b[39mself\u001b[39m, tensor_index, value):\n\u001b[1;32m    681\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Sets the value of the input tensor.\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \n\u001b[1;32m    683\u001b[0m \u001b[39m  Note this copies data in `value`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[39m    ValueError: If the interpreter could not set the tensor.\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpreter\u001b[39m.\u001b[39;49mSetTensor(tensor_index, value)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Got value of type FLOAT64 but expected type FLOAT32 for input 0, name: serving_default_images:0 "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage import io\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"food_classifier.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Load the image to be classified.\n",
    "image_url = \"foodImage.jpeg\"\n",
    "image = np.asarray(io.imread(image_url), dtype=\"float\")\n",
    "image = cv2.resize(image, dsize=input_shape, interpolation=cv2.INTER_CUBIC)\n",
    "image = image / image.max()\n",
    "image = np.expand_dims(image, 0)\n",
    "\n",
    "# Set the input tensor.\n",
    "interpreter.set_tensor(input_details[0]['index'], image)\n",
    "\n",
    "# Invoke the interpreter.\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor.\n",
    "output = interpreter.get_tensor(output_details[0]['index'])\n",
    "predicted_index = np.argmax(output)\n",
    "classes = list(pd.read_csv(labelmap_url)[\"name\"])\n",
    "print(\"Prediction: \", classes[predicted_index])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
